# 硬體友好型 Bicubic 插值演算法優化 - Python 模擬總結

## 1. 項目目標回顧

本項目的目標是開發一種適合在硬體（如FPGA）上實現的優化 Bicubic 插值演算法。我們使用 Python 進行模擬，以證明該優化演算法在保持可接受圖像品質的前提下，相對於傳統的、直接映射的 Bicubic 演算法，在硬體相關的關鍵指標（如計算複雜度、記憶體帶寬需求）上具有優勢。

## 2. 傳統 Bicubic 演算法基準

*   我們首先實現了一個標準的浮點 Bicubic 插值演算法 (`src/traditional_bicubic.py`)，採用常用的 `a=-0.5` 卷積核參數。
*   為了驗證其正確性，將其輸出與 Python 圖像處理庫 Pillow 的 `BICUBIC` 方法進行了比較。對於測試圖像 (`images/gradient.png`，64x64，1.5倍縮放)，兩者輸出的 PSNR 約為 **49.98 dB** (MSE ≈ 0.65)，表明我們的浮點基準實現是準確的。

## 3. 硬體友好型 Bicubic 演算法的設計與優化

基於傳統浮點演算法，我們設計並實現了一個硬體友好的版本 (`src/hardware_friendly_bicubic.py`)，主要包含以下優化：

### 3.1. 定點化 (Fixed-Point Arithmetic)

*   **策略**: 所有浮點運算（包括輸入的小數座標、三次卷積核函數內部計算、插值權重計算以及最終的像素值混合）都被轉換為定點整數運算。
*   **參數**: 選擇了 **8位小數精度** (`F_BITS = 8`)，即所有小數乘以 `2^8 = 256` 後取整進行運算。
*   **圖像品質**: 通過模擬比較（詳見 `tests/test_hardware_friendly_bicubic.py` 和 `compare_algorithms.py`），定點版本與我們的浮點基準版本相比，PSNR 仍高達約 **49.18 dB** (MSE ≈ 0.78)。這證明了在8位小數精度下，圖像品質的損失非常小，肉眼基本無法分辨。

### 3.2. 乘法簡化 (Multiplication Simplification)

*   **卷積核函數內部**: 在定點化的 `cubic_kernel_fixed_point` 函數中，原先與常數係數（例如，當 `a=-0.5` 時，對應的 `1.5`, `2.5`, `-0.5`, `-4.0` 等）的乘法運算，被明確地替換為硬體實現更高效的 **位移 (shift)** 和 **整數加/減 (add/sub)** 操作。
*   **核心插值計算**: 在計算最終像素值的加權平均 (`wy^T * p * wx`) 時，原來的20次浮點乘法被替換為20次定點整數乘法。具體來說，是8位無符號整數的像素值與定點表示的權重（例如 `QsX.8` 格式，即帶符號，X位整數，8位小數）進行整數乘法。
*   **硬體影響**:
    *   顯著減少或完全消除了對資源消耗較大的浮點運算單元（特別是 DSP Slices）的需求。
    *   替換為的移位器、整數加法器和小型整數乘法器通常速度更快、面積更小、功耗更低。

### 3.3. 記憶體訪問優化 (Memory Access Optimization using Line Buffers)

*   **策略**: 分析了 Bicubic 插值在讀取輸入像素時的數據重用模式。為了利用這種重用，模擬了在硬體中常用的 **行緩衝區 (line buffer)** 機制。行緩衝區使用片上記憶體 (如 FPGA 中的 BRAM) 暫存最近訪問的幾行輸入圖像數據。
*   **模擬結果**: 針對64x64圖像進行1.5倍縮放（輸出96x96圖像）的場景：
    *   無緩衝（假設每次計算輸出像素都從主記憶體讀取其所需的4x4=16個鄰域像素）：主記憶體像素讀取次數約為 **147,456** 次。
    *   有行緩衝（假設僅在需要新行時才從主記憶體整行讀入片上緩衝區）：主記憶體像素讀取次數減少至約 **4,556** 次。
    *   **帶寬需求減少了約 32.37 倍**。
*   **硬體影響**:
    *   極大地降低了對外部主記憶體（如 DDR SDRAM）的帶寬壓力。
    *   顯著降低因記憶體瓶頸導致的延遲，從而提高系統整體吞吐量。
    *   減少高功耗的外部記憶體訪問次數，有助於降低系統總功耗。
    *   BRAM 被高效利用，這是 FPGA 設計中的常見且推薦的做法。

## 4. Python 模擬結果匯總 (基於 `compare_algorithms.py`)

| 指標                     | 浮點 vs Pillow | 定點 vs Pillow | 定點 vs 浮點 (自實現) | 備註                                   |
| ------------------------ | -------------- | -------------- | ----------------------- | -------------------------------------- |
| PSNR (dB)                | 49.98          | 55.55          | 49.18                   | 越高越好                               |
| MSE                      | 0.65           | 0.18           | 0.78                    | 越低越好                               |
| **記憶體訪問減少因子**   | -              | -              | **約 32.37x**           | 相對於無緩衝的 naïve 實現             |

*   **計算複雜度**: 定性分析確認，硬體友好型設計通過將浮點運算替換為定點整數運算和位移運算，簡化了算術邏輯。
*   **執行時間**: Python 環境下的執行時間 (`float`: ~0.46s, `fixed-point`: ~0.31s, `Pillow`: ~0.0002s) 並不直接反映硬體性能，僅用於驗證演算法邏輯。

## 5. 結論與硬體優勢展望

通過本次 Python 模擬，我們成功地設計並驗證了一種硬體友好的 Bicubic 插值演算法。該演算法在保持與傳統浮點實現高度相似的圖像輸出品質的前提下，展現出在硬體實現方面的顯著潛在優勢：

1.  **計算資源效率**:
    *   **DSP 使用**: 大幅減少。浮點係數乘法被消除，核心插值的浮點乘法轉為整數乘法，這可以用更少的 DSP Slices 或僅用 LUT 實現的小型乘法器完成。
    *   **邏輯單元**: 移位和整數加減運算主要消耗 LUT 和 FF 資源。

2.  **性能提升**:
    *   **時鐘頻率**: 更簡單的定點算術運算通常具有更短的關鍵路徑延遲，有助於實現更高的系統時鐘頻率。
    *   **吞吐量**: 記憶體帶寬需求的急劇下降（約32倍）意味著處理單元因等待數據而空閒的時間大大減少，從而可以直接提升數據處理的吞吐量。

3.  **功耗降低**:
    *   **外部記憶體訪問**: 這是片上系統功耗的主要來源之一。大幅減少訪問次數將直接降低功耗。
    *   **計算單元**: 定點和整數運算單元的功耗通常低於等效的浮點運算單元。

4.  **實現面積**:
    *   由於計算單元的簡化和對 DSP 依賴的減少，預期在 FPGA 或 ASIC 上實現時，可以佔用更小的晶片面積。

該 Python 模擬項目為後續的 Verilog HDL 硬體實現提供了一個經過充分驗證和優化的演算法藍圖。模擬中確定的定點位寬、捨入策略以及算術簡化技巧（如移位代替乘法）都可以直接指導硬體設計。這為開發出一個高性能、低功耗、資源高效的 Bicubic 插值硬體 IP 核奠定了堅實的基礎。
